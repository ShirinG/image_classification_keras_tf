{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# image processing\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# pretrained nets\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from\n",
    "# https://thispointer.com/python-how-to-get-list-of-files-in-directory-and-sub-directories/\n",
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    listOfFile = [item for item in os.listdir(dirName) if not item.startswith('.')]\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "            \n",
    "    allFiles = [each for each in allFiles if each.endswith((\".jpg\", \".jpeg\", \".png\"))]           \n",
    "    return allFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 100, 100\n",
    "\n",
    "train_image_files_path = \"/keras2production/fruits/Training/\"\n",
    "valid_image_files_path = \"/keras2production/fruits/Test/\"\n",
    "\n",
    "train_images = getListOfFiles(train_image_files_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "https://keras.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_list = [\"Apricot\", \"Avocado\", \"Banana\", \"Clementine\", \"Cocos\", \"Kiwi\", \"Lemon\", \"Limes\", \n",
    "              \"Mandarine\", \"Orange\", \"Peach\", \"Pineapple\", \"Plum\", \"Pomegranate\", \"Raspberry\", \"Strawberry\"]\n",
    "output_n = len(fruit_list)\n",
    "size = 20\n",
    "img_width = 20\n",
    "img_height = 20\n",
    "channels = 3\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained nets\n",
    "\n",
    "https://keras.io/applications/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify VGG16\n",
    "\n",
    "- transfer learning (freeze all but the penultimate layer and re-train the last Dense layer) and \n",
    "- fine tuning (un-freeze the lower convolutional layers and retrain more layers)\n",
    "\n",
    "Validation set: fit_generator has no option validation_split\n",
    "\n",
    "https://keras.io/applications/#usage-examples-for-image-classification-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important: exclude top layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(75, 75, 3))\n",
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers except the last 4 layers\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7709 images belonging to 16 classes.\n",
      "Found 2428 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale = 1 / 255\n",
    ")\n",
    "\n",
    "valid_data_gen = ImageDataGenerator(\n",
    "    rescale = 1 / 255\n",
    ")\n",
    "\n",
    "train_image_array_gen = train_data_gen.flow_from_directory(\n",
    "    train_image_files_path,\n",
    "    target_size = (75,75),\n",
    "    class_mode = 'categorical',\n",
    "    classes = fruit_list,\n",
    "    color_mode = 'rgb', \n",
    "    batch_size = batch_size,\n",
    "    seed = 42)\n",
    "\n",
    "valid_image_array_gen = valid_data_gen.flow_from_directory(\n",
    "    valid_image_files_path,\n",
    "    target_size = (75,75),\n",
    "    class_mode = 'categorical',\n",
    "    classes = fruit_list,\n",
    "    color_mode = 'rgb', \n",
    "    batch_size = batch_size,\n",
    "    seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:(75, 75, 3)\n",
      "Number of classes:16\n",
      "Classes:{'Apricot': 0, 'Avocado': 1, 'Banana': 2, 'Clementine': 3, 'Cocos': 4, 'Kiwi': 5, 'Lemon': 6, 'Limes': 7, 'Mandarine': 8, 'Orange': 9, 'Peach': 10, 'Pineapple': 11, 'Plum': 12, 'Pomegranate': 13, 'Raspberry': 14, 'Strawberry': 15}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape = train_image_array_gen.image_shape\n",
    "classes = train_image_array_gen.class_indices\n",
    "num_classes = len(classes)\n",
    "class_counts = np.unique(train_image_array_gen.classes, return_counts=True)[1]\n",
    "print(\"Shape:\" + str(input_shape))\n",
    "print(\"Number of classes:\" + str(num_classes))\n",
    "print(\"Classes:\" + str(classes))\n",
    "\n",
    "chart = plt.bar(classes.keys(), class_counts)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show(chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7709 2428\n"
     ]
    }
   ],
   "source": [
    "batch_size = 24\n",
    "train_samples = train_image_array_gen.n\n",
    "valid_samples = valid_image_array_gen.n\n",
    "print(train_samples, valid_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 519)               1063431   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 519)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                8320      \n",
      "=================================================================\n",
      "Total params: 15,786,439\n",
      "Trainable params: 8,151,175\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    " \n",
    "# Add the base model\n",
    "model.add(base_model)\n",
    " \n",
    "# Add new layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(519, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_n, activation='softmax'))\n",
    " \n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = RMSprop(lr = 0.0001, decay = 1e-6),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "251/321 [======================>.......] - ETA: 1:23 - loss: 0.5516 - acc: 0.8374"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a30d174a6483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_image_array_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_samples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_image_array_gen,\n",
    "    steps_per_epoch = int(train_samples / batch_size), \n",
    "    epochs = 10, \n",
    "    validation_data = valid_image_array_gen,\n",
    "    validation_steps = int(valid_samples / batch_size),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc = 'lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
