{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import hashing_trick\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text data\n",
    "\n",
    "https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Review Text  Recommended IND\n",
      "0  Absolutely wonderful - silky and sexy and comf...                1\n",
      "1  Love this dress!  it's sooo pretty.  i happene...                1\n",
      "2  I had such high hopes for this dress and reall...                0\n",
      "3  I love, love, love this jumpsuit. it's fun, fl...                1\n",
      "4  This shirt is very flattering to all due to th...                1\n"
     ]
    }
   ],
   "source": [
    "# Read in only the two columns we need \n",
    "reviews = pd.read_csv('data/Womens Clothing E-Commerce Reviews.csv',\n",
    "                     usecols = ['Review Text', 'Recommended IND'])\n",
    "print(reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1a8744e630>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, g = plt.subplots(figsize=(12, 9))\n",
    "reviews['Recommended IND'].value_counts().head(10).plot.bar(color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 23486 reviews\n",
      "The reviews add up to 7015023 characters\n"
     ]
    }
   ],
   "source": [
    "# just text\n",
    "text = reviews['Review Text']\n",
    "\n",
    "n_reviews = len(text)\n",
    "n_chars = len(' '.join(map(str, text)))\n",
    "\n",
    "print(\"We have %d reviews\" % n_reviews)\n",
    "print(\"The reviews add up to %d characters\" % n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Absolutely wonderful - silky and sexy and comfortable',\n",
       " 'Love this dress!  it\\'s sooo pretty.  i happened to find it in a store, and i\\'m glad i did bc i never would have ordered it online bc it\\'s petite.  i bought a petite and am 5\\'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.',\n",
       " 'I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c',\n",
       " \"I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!\",\n",
       " 'This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!',\n",
       " 'I love tracy reese dresses, but this one is not for the very petite. i am just under 5 feet tall and usually wear a 0p in this brand. this dress was very pretty out of the package but its a lot of dress. the skirt is long and very full so it overwhelmed my small frame. not a stranger to alterations, shortening and narrowing the skirt would take away from the embellishment of the garment. i love the color and the idea of the style but it just did not work on me. i returned this dress.',\n",
       " 'I aded this in my basket at hte last mintue to see what it would look like in person. (store pick up). i went with teh darkler color only because i am so pale :-) hte color is really gorgeous, and turns out it mathced everythiing i was trying on with it prefectly. it is a little baggy on me and hte xs is hte msallet size (bummer, no petite). i decided to jkeep it though, because as i said, it matvehd everything. my ejans, pants, and the 3 skirts i waas trying on (of which i ]kept all ) oops.',\n",
       " \"I ordered this in carbon for store pick up, and had a ton of stuff (as always) to try on and used this top to pair (skirts and pants). everything went with it. the color is really nice charcoal with shimmer, and went well with pencil skirts, flare pants, etc. my only compaint is it is a bit big, sleeves are long and it doesn't go in petite. also a bit loose for me, but no xxs... so i kept it and wil ldecide later since the light color is already sold out in hte smallest size...\",\n",
       " 'I love this dress. i usually get an xs but it runs a little snug in bust so i ordered up a size. very flattering and feminine with the usual retailer flair for style.',\n",
       " 'I\\'m 5\"5\\' and 125 lbs. i ordered the s petite to make sure the length wasn\\'t too long. i typically wear an xs regular in retailer dresses. if you\\'re less busty (34b cup or smaller), a s petite will fit you perfectly (snug, but not tight). i love that i could dress it up for a party, or down for work. i love that the tulle is longer then the fabric underneath.']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's reduce the size to make training faster\n",
    "# take the first 20% of reviews\n",
    "sample_size = int(len(text) * 0.2)\n",
    "\n",
    "text = text[:sample_size].values\n",
    "text = text.tolist()\n",
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4697"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['absolutely', 'wonderful', 'silky', 'and', 'sexy', 'and', 'comfortable'], ['love', 'this', 'dress', \"it's\", 'sooo', 'pretty', 'i', 'happened', 'to', 'find', 'it', 'in', 'a', 'store', 'and', \"i'm\", 'glad', 'i', 'did', 'bc', 'i', 'never', 'would', 'have', 'ordered', 'it', 'online', 'bc', \"it's\", 'petite', 'i', 'bought', 'a', 'petite', 'and', 'am', \"5'8\", 'i', 'love', 'the', 'length', 'on', 'me', 'hits', 'just', 'a', 'little', 'below', 'the', 'knee', 'would', 'definitely', 'be', 'a', 'true', 'midi', 'on', 'someone', 'who', 'is', 'truly', 'petite'], ['i', 'had', 'such', 'high', 'hopes', 'for', 'this', 'dress', 'and', 'really', 'wanted', 'it', 'to', 'work', 'for', 'me', 'i', 'initially', 'ordered', 'the', 'petite', 'small', 'my', 'usual', 'size', 'but', 'i', 'found', 'this', 'to', 'be', 'outrageously', 'small', 'so', 'small', 'in', 'fact', 'that', 'i', 'could', 'not', 'zip', 'it', 'up', 'i', 'reordered', 'it', 'in', 'petite', 'medium', 'which', 'was', 'just', 'ok', 'overall', 'the', 'top', 'half', 'was', 'comfortable', 'and', 'fit', 'nicely', 'but', 'the', 'bottom', 'half', 'had', 'a', 'very', 'tight', 'under', 'layer', 'and', 'several', 'somewhat', 'cheap', 'net', 'over', 'layers', 'imo', 'a', 'major', 'design', 'flaw', 'was', 'the', 'net', 'over', 'layer', 'sewn', 'directly', 'into', 'the', 'zipper', 'it', 'c']]\n"
     ]
    }
   ],
   "source": [
    "# clean document\n",
    "\n",
    "words = list()\n",
    "\n",
    "for i in range(len(text)):\n",
    "        tokens = text_to_word_sequence(str(text[i]))\n",
    "        #print(tokens)\n",
    "        words.append(tokens)\n",
    "\n",
    "print(words[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tokenizer\n",
    "t = Tokenizer()\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4697\n"
     ]
    }
   ],
   "source": [
    "# summarize what was learned\n",
    "#print(t.word_counts)\n",
    "print(t.document_count)\n",
    "#print(t.word_index)\n",
    "#print(t.word_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4697\n",
      "[[ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  2.  5. ...  0.  0.  0.]\n",
      " [ 0.  5.  5. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  5.  4. ...  1.  1.  0.]\n",
      " [ 0.  2.  2. ...  0.  0.  0.]\n",
      " [ 0. 10.  2. ...  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode documents\n",
    "encoded_docs = t.texts_to_matrix(words, mode='count')\n",
    "print(len(encoded_docs))\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4697\n",
      "[1 1 0 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "response = reviews['Recommended IND']\n",
    "y_train = response[:sample_size].values\n",
    "print(len(y_train))\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4697, 7333)\n"
     ]
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(encoded_docs)\n",
    "print('x_train shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 7333\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3287 samples, validate on 1410 samples\n",
      "Epoch 1/2\n",
      "3287/3287 [==============================] - 206s 63ms/step - loss: 0.4906 - acc: 0.8144 - val_loss: 0.4614 - val_acc: 0.8284\n",
      "Epoch 2/2\n",
      "3287/3287 [==============================] - 206s 63ms/step - loss: 0.4789 - acc: 0.8181 - val_loss: 0.4744 - val_acc: 0.8284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1a839edda0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
